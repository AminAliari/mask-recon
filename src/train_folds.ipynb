{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mask_dataset\n",
                "from config import config\n",
                "from model import MaskCNN\n",
                "\n",
                "import os\n",
                "import random\n",
                "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.model_selection import KFold\n",
                "from torch.utils.data import DataLoader, SubsetRandomSampler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<torch._C.Generator at 0x225b3708af8>"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "random.seed(config.random_seed)\n",
                "torch.manual_seed(config.random_seed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda:0\n"
                    ]
                }
            ],
            "source": [
                "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
                "print(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = mask_dataset.MaskDataset(root_dir='../dataset', img_dim=config.img_dim)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "foldperf = {}\n",
                "splits = KFold(n_splits=10, shuffle=True, random_state=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fold 1\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.016 AVG Training Acc 60.19 % AVG Test Acc 58.67 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.014 AVG Training Acc 79.93 % AVG Test Acc 71.00 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.012 AVG Training Acc 91.93 % AVG Test Acc 73.67 %\n",
                        "Fold 2\n",
                        "Epoch:1/3 AVG Training Loss:0.016 AVG Test Loss:0.017 AVG Training Acc 58.56 % AVG Test Acc 55.00 %\n",
                        "Epoch:2/3 AVG Training Loss:0.009 AVG Test Loss:0.013 AVG Training Acc 78.52 % AVG Test Acc 69.33 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.011 AVG Training Acc 92.37 % AVG Test Acc 74.33 %\n",
                        "Fold 3\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.018 AVG Training Acc 61.30 % AVG Test Acc 53.00 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.014 AVG Training Acc 81.26 % AVG Test Acc 66.00 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.012 AVG Training Acc 91.15 % AVG Test Acc 72.67 %\n",
                        "Fold 4\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.018 AVG Training Acc 60.74 % AVG Test Acc 53.67 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.012 AVG Training Acc 81.30 % AVG Test Acc 72.00 %\n",
                        "Epoch:3/3 AVG Training Loss:0.003 AVG Test Loss:0.013 AVG Training Acc 93.67 % AVG Test Acc 72.67 %\n",
                        "Fold 5\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.017 AVG Training Acc 61.00 % AVG Test Acc 57.00 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.013 AVG Training Acc 82.07 % AVG Test Acc 68.33 %\n",
                        "Epoch:3/3 AVG Training Loss:0.003 AVG Test Loss:0.011 AVG Training Acc 94.85 % AVG Test Acc 71.33 %\n",
                        "Fold 6\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.017 AVG Training Acc 60.96 % AVG Test Acc 52.00 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.017 AVG Training Acc 81.85 % AVG Test Acc 64.00 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.013 AVG Training Acc 92.85 % AVG Test Acc 72.67 %\n",
                        "Fold 7\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.019 AVG Training Acc 60.15 % AVG Test Acc 48.00 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.012 AVG Training Acc 79.96 % AVG Test Acc 68.00 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.015 AVG Training Acc 93.19 % AVG Test Acc 68.33 %\n",
                        "Fold 8\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.019 AVG Training Acc 58.48 % AVG Test Acc 46.33 %\n",
                        "Epoch:2/3 AVG Training Loss:0.009 AVG Test Loss:0.010 AVG Training Acc 79.19 % AVG Test Acc 76.67 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.011 AVG Training Acc 92.93 % AVG Test Acc 74.33 %\n",
                        "Fold 9\n",
                        "Epoch:1/3 AVG Training Loss:0.015 AVG Test Loss:0.015 AVG Training Acc 60.15 % AVG Test Acc 63.67 %\n",
                        "Epoch:2/3 AVG Training Loss:0.008 AVG Test Loss:0.011 AVG Training Acc 79.33 % AVG Test Acc 73.67 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.010 AVG Training Acc 90.56 % AVG Test Acc 75.00 %\n",
                        "Fold 10\n",
                        "Epoch:1/3 AVG Training Loss:0.016 AVG Test Loss:0.019 AVG Training Acc 58.56 % AVG Test Acc 49.67 %\n",
                        "Epoch:2/3 AVG Training Loss:0.009 AVG Test Loss:0.012 AVG Training Acc 79.15 % AVG Test Acc 73.67 %\n",
                        "Epoch:3/3 AVG Training Loss:0.004 AVG Test Loss:0.020 AVG Training Acc 91.52 % AVG Test Acc 62.67 %\n",
                        "\n",
                        "done.\n"
                    ]
                }
            ],
            "source": [
                "avg_loss = 0\n",
                "best_vloss = 999999\n",
                "y_total_pred = []\n",
                "y_total_true = []\n",
                "\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
                "    print('Fold {}'.format(fold + 1))\n",
                "    model = MaskCNN(len(dataset.labels), config.img_dim, base_filter_size=config.base_filter_size)\n",
                "    model = model.to(device)\n",
                "\n",
                "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, sampler=torch.utils.data.SubsetRandomSampler(train_idx))\n",
                "    valid_loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, sampler=torch.utils.data.SubsetRandomSampler(val_idx))  \n",
                "\n",
                "    loss_fn = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
                "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
                "\n",
                "    for epoch in range(config.epochs):\n",
                "        # traning\n",
                "        model.train()\n",
                "        correct = 0\n",
                "        running_loss = 0.0\n",
                "        for i, data in enumerate(train_loader, 0):\n",
                "            images, labels = data[0].to(device), data[1].to(device)\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "            preds = model(images)\n",
                "            loss = loss_fn(preds, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            correct += (torch.max(preds, dim=1)[1] == labels).sum().item()\n",
                "\n",
                "            running_loss += loss.item()\n",
                "            preds = torch.argmax(preds.data, dim=1)\n",
                "            y_total_true.extend(labels.data.cpu().numpy())\n",
                "            y_total_pred.extend(preds.data.cpu().numpy())\n",
                "\n",
                "        # validation\n",
                "        model.eval()\n",
                "        val_correct = 0\n",
                "        running_vloss = 0\n",
                "        with torch.no_grad():\n",
                "            for i, vdata in enumerate(valid_loader):\n",
                "                vimages, vlabels = vdata[0].to(device), vdata[1].to(device)\n",
                "                vpreds = model(vimages)\n",
                "                vloss = loss_fn(vpreds, vlabels)\n",
                "                running_vloss += vloss.item()\n",
                "                val_correct += (torch.max(vpreds, dim=1)[1] == vlabels).sum().item()\n",
                "                vpreds = torch.argmax(vpreds.data, dim=1)\n",
                "                y_total_true.extend(vlabels.data.cpu().numpy())\n",
                "                y_total_pred.extend(vpreds.data.cpu().numpy())\n",
                "        running_loss = running_loss / len(train_loader.sampler)\n",
                "        train_acc = correct / len(train_loader.sampler) * 100\n",
                "        running_vloss = running_vloss / len(valid_loader.sampler)\n",
                "        val_acc = val_correct / len(valid_loader.sampler) * 100\n",
                "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
                "                                                                                                                                 config.epochs,\n",
                "                                                                                                                                 running_loss,\n",
                "                                                                                                                                 running_vloss,\n",
                "                                                                                                                                 train_acc,\n",
                "                                                                                                                                 val_acc))\n",
                "        history['train_loss'].append(running_loss)\n",
                "        history['test_loss'].append(running_vloss)\n",
                "        history['train_acc'].append(train_acc)\n",
                "        history['test_acc'].append(val_acc)\n",
                "\n",
                "    foldperf['fold{}'.format(fold+1)] = history  \n",
                "\n",
                "\n",
                "torch.save(model,'MaskCNN_kfold_old.pt')\n",
                "print('\\ndone.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Performance of 10 fold cross validation\n",
                        "Average Training Loss: 0.009 \t Average Test Loss: 0.014 \t Average Training Acc: 77.59 \t Average Test Acc: 65.24\n"
                    ]
                }
            ],
            "source": [
                "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
                "k = 10\n",
                "for f in range(1,k+1):\n",
                "\n",
                "     tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
                "     testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
                "\n",
                "     ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n",
                "     testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n",
                "\n",
                "print('Performance of {} fold cross validation'.format(k))\n",
                "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc: {:.2f}\".format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))     "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mask_dataset\n",
                "from config import config\n",
                "from model import MaskCNN\n",
                "\n",
                "import os\n",
                "import random\n",
                "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sn\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "accuracy: 0.764\n",
                        "recall: 0.764\n",
                        "precision: 0.766\n",
                        "f1: 0.764\n"
                    ]
                }
            ],
            "source": [
                "print(f'accuracy: {accuracy_score(y_total_true, y_total_pred):.3f}')\n",
                "print(f'recall: {recall_score(y_total_true, y_total_pred, average=\"weighted\"):.3f}')\n",
                "print(f'precision: {precision_score(y_total_true, y_total_pred, average=\"weighted\"):.3f}')\n",
                "print(f'f1: {f1_score(y_total_true, y_total_pred, average=\"weighted\"):.3f}')"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "678a7f023a315869c539266b01a0b2637ddd14761bfd019fe41760ec4e9d6b8e"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit ('base': conda)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
